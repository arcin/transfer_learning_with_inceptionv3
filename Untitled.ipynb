{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# graphing\n",
    "import matplotlib.image as mpimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# TF model stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def clear_directory(directory_path):\n",
    "    dirs_files = os.listdir(directory_path)\n",
    "    \n",
    "    for item in dirs_files:\n",
    "#         item_path = os.path.join(directory_path, item)\n",
    "        item_path = directory_path+ item\n",
    "        \n",
    "        try:\n",
    "            if os.path.isfile(item_path):\n",
    "                os.unlink(item_path)\n",
    "            elif os.path.isdir(item_path): \n",
    "                shutil.rmtree(item_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_empty_folders(path, removeRoot=True):\n",
    "    if not os.path.isdir(path):\n",
    "        return\n",
    "    \n",
    "    # remove empty subfolders\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(path, f)\n",
    "            \n",
    "            if os.path.isdir(fullpath):\n",
    "                remove_empty_folders(fullpath)\n",
    "\n",
    "    # if folder empty, delete it\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files) == 0 and removeRoot:\n",
    "        print(\"Removing empty folder:\", path)\n",
    "        os.rmdir(path)\n",
    "        \n",
    "        \n",
    "def dir_file_count(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'chest_xray/train'\n",
    "test_dir = 'chest_xray/test'\n",
    "validation_dir = 'chest_xray/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimage.imread(train_dir + '/NORMAL/IM-0115-0001.jpeg')\n",
    "image_plot = plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "def create_model(input_shape):\n",
    "    K.clear_session()\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_x = 175\n",
    "dimension_y = 175\n",
    "model = create_model((dimension_x, dimension_y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
    "training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy', dtype=tf.float32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_count(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = 1./255\n",
    "target_size = (dimension_x, dimension_y)\n",
    "batch_size = 500\n",
    "class_mode = 'categorical'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=rescale,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    class_mode=class_mode,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "val_datagen = ImageDataGenerator(rescale=rescale)\n",
    "val_generator = val_datagen.flow_from_directory(validation_dir,\n",
    "                                               target_size=target_size,\n",
    "                                               class_mode=class_mode,\n",
    "                                               batch_size=file_count(validation_dir),\n",
    "                                               shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=target_size,\n",
    "                                                  class_mode=class_mode,\n",
    "                                                  batch_size=file_count(validation_dir),\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_generator.classes\n",
    "labels = np.unique(y)\n",
    "\n",
    "train_class_weights = compute_class_weight('balanced', labels, y)\n",
    "print(train_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=len(val_generator),\n",
    "                              class_weight=train_class_weights,\n",
    "                              workers=20\n",
    "                             )\n",
    "MODEL_FILE = 'pneumonia_v1.hd5'\n",
    "model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl_score = model.predict_generator(test_generator)\n",
    "AUC = roc_auc_score(test_generator.classes, np.argmax(vl_score, axis=1))\n",
    "\n",
    "print(classification_report(test_generator.classes,\n",
    "                     np.argmax(vl_score, axis=1),\n",
    "                     target_names=['Normal', 'Pnuemonia']))\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
