{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# graphing\n",
    "import matplotlib.image as mpimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import random\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "# TF model stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions: Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory, if directory exists removes if remove parameter is set to True \n",
    "def create_directory(directory_path, remove=False):\n",
    "    if remove and os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directory_path)\n",
    "        except:\n",
    "            print(\"Could not create directory: \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "# Removes directory, if directory exists \n",
    "def remove_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except:\n",
    "            print(\"Could not remove directory : \", directory_path)\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def clear_directory(directory_path):\n",
    "    dirs_files = os.listdir(directory_path)\n",
    "    \n",
    "    for item in dirs_files:\n",
    "#         item_path = os.path.join(directory_path, item)\n",
    "        item_path = directory_path+ item\n",
    "        \n",
    "        try:\n",
    "            if os.path.isfile(item_path):\n",
    "                os.unlink(item_path)\n",
    "            elif os.path.isdir(item_path): \n",
    "                shutil.rmtree(item_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_empty_folders(path, removeRoot=True):\n",
    "    if not os.path.isdir(path):\n",
    "        return\n",
    "    \n",
    "    # remove empty subfolders\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(path, f)\n",
    "            \n",
    "            if os.path.isdir(fullpath):\n",
    "                remove_empty_folders(fullpath)\n",
    "\n",
    "    # if folder empty, delete it\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    if len(files) == 0 and removeRoot:\n",
    "        print(\"Removing empty folder:\", path)\n",
    "        os.rmdir(path)\n",
    "        \n",
    "        \n",
    "def dir_file_count(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "# Removes everything except alphabetical and selected characters from name string\n",
    "def name_correct(name):\n",
    "    return re.sub(r'[^a-zA-Z,:]', ' ', name).title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reset_subplot_params(nrows, ncols, dpi):\n",
    "    subplot_params = {}\n",
    "    subplot_params[\"nrows\"] = nrows\n",
    "    subplot_params[\"ncols\"] = ncols\n",
    "\n",
    "    subplot_params[\"figsize_col\"] = subplot_params[\"ncols\"]*2.5\n",
    "    subplot_params[\"figsize_row\"] = subplot_params[\"nrows\"]*2.5\n",
    "    subplot_params[\"dpi\"] = dpi\n",
    "    subplot_params[\"facecolor\"] = 'w'\n",
    "    subplot_params[\"edgecolor\"] = 'k'\n",
    "    subplot_params[\"subplot_kw\"] = {'xticks': [], 'yticks': []}\n",
    "    subplot_params[\"axes.titlesize\"] = 'small'\n",
    "    subplot_params[\"hspace\"] = 0.5\n",
    "    subplot_params[\"wspace\"] = 0.3\n",
    "    \n",
    "    return subplot_params\n",
    "\n",
    "def get_reset_plot_params(figsize=(15, 5), title=\"\", xlabel =\"\", ylabel=\"\", legends=[], title_fontsize = 18, label_fontsize = 14, image_file_name=\"\", save = False, dpi=100, update_image=True):\n",
    "    plot_params = {}\n",
    "    \n",
    "    plot_params[\"figsize\"] = figsize\n",
    "    \n",
    "    plot_params[\"title\"] = title\n",
    "    \n",
    "    plot_params[\"xlabel\"] = xlabel\n",
    "    plot_params[\"ylabel\"] = ylabel\n",
    "    \n",
    "    plot_params[\"legends\"] = legends \n",
    "    \n",
    "    plot_params[\"title_fontsize\"] = title_fontsize\n",
    "    plot_params[\"axes.titlesize\"] = \"small\"\n",
    "    plot_params[\"label_fontsize\"] = label_fontsize\n",
    "    \n",
    "    plot_params[\"image_file_name\"] = image_file_name\n",
    "    plot_params[\"save\"] = save\n",
    "    plot_params[\"update_image\"] = update_image\n",
    "    \n",
    "    plot_params[\"subplot\"] = None\n",
    "    return plot_params\n",
    "\n",
    "def select_image_by_category(image_dir, image_count_per_category):\n",
    "    classes = os.listdir(image_dir)\n",
    "    class_count = len(classes)\n",
    "\n",
    "    image_file_paths = {}\n",
    "    \n",
    "    for i in range(class_count):\n",
    "        subdir_path = image_dir+\"/\"+classes[i]\n",
    "        subdir_files = os.listdir(subdir_path)\n",
    "\n",
    "        subdir_file_count = len(subdir_files)\n",
    "\n",
    "        subdir_file_mem = {}\n",
    "        \n",
    "        subdir_file_index = -1\n",
    "        \n",
    "        image_file_paths[classes[i]] = []\n",
    "        \n",
    "        for j in range(image_count_per_category):\n",
    "            while subdir_file_index in subdir_file_mem:\n",
    "                subdir_file_index = random.randint(0, subdir_file_count-1)\n",
    "                \n",
    "            subdir_file_mem[subdir_file_index] = 1\n",
    "            \n",
    "            subdir_file_name = subdir_files[subdir_file_index]\n",
    "            subdir_file_path = subdir_path+ \"/\" + subdir_file_name\n",
    "\n",
    "            image_file_paths[classes[i]].append(subdir_file_path)\n",
    "            \n",
    "    return image_file_paths\n",
    "\n",
    "\n",
    "def get_fig_axs(subplot_params):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=subplot_params[\"nrows\"], ncols=subplot_params[\"ncols\"], \n",
    "        figsize=(subplot_params[\"figsize_col\"], subplot_params[\"figsize_row\"]),\n",
    "        dpi=subplot_params[\"dpi\"], facecolor=subplot_params[\"facecolor\"], \n",
    "        edgecolor=subplot_params[\"edgecolor\"], subplot_kw=subplot_params[\"subplot_kw\"])\n",
    "        \n",
    "    return fig, axs\n",
    "    \n",
    "\n",
    "def plot_sample_image(image_file_paths, plot_params, subplot_params, update_image=True):\n",
    "    fig, axs = get_fig_axs(subplot_params)\n",
    "\n",
    "    plt.rcParams.update({'axes.titlesize': plot_params[\"axes.titlesize\"]})\n",
    "    plt.subplots_adjust(hspace=subplot_params[\"hspace\"], wspace=subplot_params[\"wspace\"])\n",
    "\n",
    "\n",
    "    i=0\n",
    "    for img_filepath in image_file_paths:\n",
    "        img = cv2.imread(img_filepath, 1)\n",
    "        plt.title(img_filepath.split(\"/\")[-1])\n",
    "        plt.subplot(subplot_params[\"nrows\"], subplot_params[\"ncols\"], i+1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "    if plot_params[\"update_image\"] and os.path.exists(plot_params[\"image_file_name\"]):\n",
    "        os.remove(plot_params[\"image_file_name\"])  \n",
    "    if plot_params[\"save\"]:\n",
    "        fig.savefig(plot_params[\"image_file_name\"], dpi=plot_params[\"dpi\"])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def show_class_sample_images(directory, image_count_per_category=5, save=False, dpi=100, update_image=False):\n",
    "    class_count = len(os.listdir(directory))\n",
    "    print(\"Number of Class: \", class_count)\n",
    "    sample_img_by_class = select_image_by_category(directory, image_count_per_category)\n",
    "    for class_name in sample_img_by_class:\n",
    "        plot_params = get_reset_plot_params(image_file_name=\"img.png\", save = save, dpi=dpi, update_image=update_image)\n",
    "        subplot_params = get_reset_subplot_params(nrows=1, ncols=image_count_per_category, dpi=dpi)\n",
    "        print(\"%s%s%s\"%(\"-\"*55, name_correct(class_name), \"-\"*55))\n",
    "        plot_sample_image(sample_img_by_class[class_name], plot_params, subplot_params)\n",
    "        print(\"\")\n",
    "    print(\"%s%s%d%s\"%(\"-\"*55, \"All Class Printed:\", class_count, \"-\"*55))\n",
    "    \n",
    "# count number of files in each subdirectory of a directory\n",
    "def subdirectory_file_count(master_directory):\n",
    "    subdirectories = os.listdir(master_directory)\n",
    "    subdirectory_count = len(subdirectories)\n",
    "\n",
    "    subdirectory_names = []\n",
    "    subdirectory_file_counts = []\n",
    "\n",
    "    for subdirectory in subdirectories:\n",
    "        current_directory = os.path.join(master_directory, subdirectory)\n",
    "        file_count = len(os.listdir(current_directory))\n",
    "        subdirectory_names.append(subdirectory)\n",
    "        subdirectory_file_counts.append(file_count)\n",
    "    \n",
    "    return subdirectory_names, subdirectory_file_counts\n",
    "         \n",
    "    \n",
    "\n",
    "# show barplot\n",
    "def bar_plot(x, y, plot_property):\n",
    "    if plot_property['subplot']:\n",
    "        plt.subplot(plot_property['subplot'])\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.title(plot_property['title'], fontsize=plot_property['title_fontsize'])\n",
    "    plt.xlabel(plot_property['xlabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.ylabel(plot_property['ylabel'], fontsize=plot_property['label_fontsize'])\n",
    "    plt.xticks(range(len(x)), x)\n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a directory\n",
    "def count_bar_plot(master_directory, plot_property):\n",
    "    dir_name, dir_file_count = subdirectory_file_count(master_directory)\n",
    "    x = [name_correct(i) for i in dir_name]\n",
    "    # x = dir_name\n",
    "    y = dir_file_count\n",
    "    bar_plot(x, y, plot_property)\n",
    "    \n",
    "    \n",
    "# show bar plot for count of labels in subdirectory of a training, validation, testing directory    \n",
    "def show_train_val_test(training_dir, validation_dir, testing_dir, plot_property):\n",
    "    plt.figure(figsize=plot_property['figsize'])\n",
    "    \n",
    "    title = plot_property['title']\n",
    "    plot_property['title'] = title + \" (Training)\"\n",
    "    subplot_no = plot_property['subplot'] \n",
    "\n",
    "    count_bar_plot(training_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title + \" (Validation)\"\n",
    "    plot_property['subplot'] = subplot_no+1\n",
    "    count_bar_plot(validation_dir, plot_property)\n",
    "    \n",
    "    \n",
    "    plot_property['title'] = title + \" (Testing)\"\n",
    "    plot_property['subplot'] = subplot_no + 2\n",
    "    count_bar_plot(testing_dir, plot_property)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# reset tensorflow graph tp free up memory and resource allocation \n",
    "def reset_graph(model=None):\n",
    "    if model:\n",
    "        try:\n",
    "            del model\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# reset callbacks \n",
    "def reset_callbacks(checkpoint=None, reduce_lr=None, early_stopping=None, tensorboard=None):\n",
    "    checkpoint = None\n",
    "    reduce_lr = None\n",
    "    early_stopping = None\n",
    "    tensorboard = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "reset_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'chest_xray/train'\n",
    "test_dir = 'chest_xray/test'\n",
    "validation_dir = 'chest_xray/val'\n",
    "output_dir = \"data/output\"\n",
    "figure_directory = \"data/output/figures\"\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)\n",
    "\n",
    "file_name_pred_batch = figure_directory+\"/result\"\n",
    "file_name_pred_sample = figure_directory+\"/sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use helper functions to display some of the training data.\n",
    "- xrays of neumonia\n",
    "- xrays of no infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_sample_images(train_dir, image_count_per_category=5, save=False, dpi=100, update_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Compile model using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "def create_model(input_shape):\n",
    "    K.clear_session()\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    \"\"\"\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \"\"\"\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    predictions = Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_x = 150\n",
    "dimension_y = 150\n",
    "model = create_model((dimension_x, dimension_y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
    "training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy', dtype=tf.float32)\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy', dtype=tf.float32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = 1./255\n",
    "target_size = (dimension_x, dimension_y)\n",
    "batch_size = 500\n",
    "class_mode = 'categorical'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=rescale,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=target_size,\n",
    "                                                    class_mode=class_mode,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "val_datagen = ImageDataGenerator(rescale=rescale)\n",
    "val_generator = val_datagen.flow_from_directory(validation_dir,\n",
    "                                               target_size=target_size,\n",
    "                                               class_mode=class_mode,\n",
    "                                               batch_size=dir_file_count(validation_dir),\n",
    "                                               shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=target_size,\n",
    "                                                  class_mode=class_mode,\n",
    "                                                  batch_size=dir_file_count(validation_dir),\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_generator.classes\n",
    "labels = np.unique(y)\n",
    "\n",
    "train_class_weights = compute_class_weight('balanced', labels, y)\n",
    "print(train_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=len(val_generator),\n",
    "                              class_weight=train_class_weights,\n",
    "                              workers=20\n",
    "                             )\n",
    "MODEL_FILE = 'pneumonia_v1.hd5'\n",
    "model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vl_score = model.predict_generator(test_generator)\n",
    "AUC = roc_auc_score(test_generator.classes, np.argmax(vl_score, axis=1))\n",
    "\n",
    "print(classification_report(test_generator.classes,\n",
    "                     np.argmax(vl_score, axis=1),\n",
    "                     target_names=['Normal', 'Pnuemonia']))\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
